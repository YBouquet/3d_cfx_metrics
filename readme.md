Certainly! Here's an enhanced version of your Markdown:

# Metrics API for the 3D Counterfactual Generation Project

## Overview
This library aims to provide comprehensive metrics for evaluating a counterfactual generative pipeline for 3D point clouds.

## Tutorial

### Table of Contents
- [Dataset](#dataset)
- [Metric](#metric)
  - [Overview](#overview)
  - [Flip Rate](#flip-rate)
  - [P Norm](#p-norm)
  - [Chamfer Distance](#chamfer-distance)
  - [LPIPS](#lpips)

### Dataset

#### Overview
The expected output format for any pipeline undergoing evaluation is as follows:
```json
{
  "dataset": "ShapeNet",
  "type": "chair", // Point cloud's class
  "split": "train", // or "test"
  "latent_code_original": ndarray,
  "latent_code_init": ndarray,
  "latent_code_ce": ndarray,
  "point_cloud_original": ndarray,
  "point_cloud_ce": ndarray,
  "logit_original": float,
  "logit_ce": float,
  "max_number_of_steps": int, // Number of maximum optimizing steps allowed during the generation process
  "number_of_steps_flip": int, // Number of steps needed during optimization to have a valid counterfactual
  "things_for_normalization": ndarray // Values (mean, std, etc.) to normalize the point clouds
}
```
Each counterfactual should be saved in an independent file, under the following name: `"{experiment}/{sample_id}_{counterfactual_id}.pkl"`

To handle this data structure, we provide a class `CounterFactualData` that extends the `torch.utils.data.Dataset` class. To load all samples generated by a pipeline during an experiment, create an instance of this class, informing the correct experiment path to the constructor. Then, generate a `torch.utils.data.DataLoader` instance from the resulting instance.

[Back to Table of Contents](#table-of-contents)

### Metric

#### Overview
An interface, the Metric class, serves for defining metrics in experiments. It provides methods to evaluate the metric and retrieve the evaluation results using the method: 
```python
evaluate(self, dataloader: DataLoader, verbose: bool = True) -> Dict
```
This method evaluates the metric using the provided DataLoader and returns the result in a dictionary with respect to the inheritance class.

The following metrics are implemented:
- [Flip Rate](#flip-rate)
- [P Norm](#p-norm)
- [Chamfer Distance](#chamfer-distance)
- [LPIPS](#lpips)

#### Flip Rate
#### P Norm
#### Chamfer Distance
#### LPIPS

[Back to Table of Contents](#table-of-contents)
